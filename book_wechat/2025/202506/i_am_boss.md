## 用上 AI 之后，感觉自己越来越像老板了

要说员工和老板的最大区别，有人认为是权力不对等，有人认为是收入上的差距，但我更认为，最大的区别在于老板负责决策，而员工侧重执行。也就是，我们常说的“拍板还得老板来”。

一个典型的场景是：大家围坐一起讨论技术方案，讨论得热火朝天，最后问采用哪个方案时，所有人都会不约而同地望向“老大”。如果抉择关系重大，老大往往会说：“我把大家的方案汇总上去，看领导怎么安排吧。”

有人觉得当老板很轻松，随口一说，底下的人都去落地执行，成果最终归老板。然而，那些说话轻巧的人，曾经也为升学选专业、大学毕业进哪家公司而纠结良久，更别提花重金请人替自己填志愿的。这样连人生都要别人替自己做主的人，你能相信他做决策容易？

当然，人生就是如此，有时我们不得不亲自抉择。就像我开始大规模使用 AI 编程之后，每天都要不断做选择：AI 作为我的“助手”，一日之内会给出无数方案，而我的工作，就是判断这些方案是否靠谱。想想想三国时期，曹操麾下群谋士三千，主意五花八门，但最终还得曹操拍板。随着 AI 的广泛应用，有一天我恍然大悟：我不就是在当老板吗？

为什么会有这种感觉？且听我细细道来。

## 揣摩圣意

一般来说，组织层级越高，下达的指令就越抽象。面对抽象的要求，员工有两种反应：一种是不敢直接发问，私下揣摩领导意图；另一种是在不清楚时立即提问，有时还会用自己的话复述一遍，让领导确认。

很多 AI 产品的表现，就像第一种类型。比如我向 DeepSeek 提问：

> 华为麒麟CPU相对于飞腾D2000，性能对比怎样？

开启“深度思考”模式后，DeepSeek 开始揣摩我的意图：

> 嗯，用户想了解华为麒麟CPU与飞腾D2000的性能对比。这个问题很具体，显然用户对国产芯片的性能差异感兴趣，可能是为了设备选购或技术研究。
>
> 从搜索结果看，正好有多个网页提供了这两款处理器的详细参数和测试数据。网页1、7、8重点描述了麒麟X90的架构和跑分，而网页1、3、9、10则详细说明了飞腾D2000的特性。需要特别注意性能测试数据的来源是否可靠——网页7提到的Geekbench 6测试结果来自博主爆料，但网页8有华为官方数据佐证，可信度较高。
>
> 用户可能更关注实际应用场景而非纯理论参数。比如网页1提到飞腾D2000在办公软件兼容性上的问题，而网页7强调麒麟X90在AI计算和跨设备协同的优势。这些实际体验差异比纸面参数更有参考价值。
>
> 比较意外的是网页10的深度测试，它用编译性能、游戏服务器启动速度等具体场景对比了飞腾D2000与Intel老款芯片的差距，这个第三方测试能很好支撑性能结论。不过要注意测试环境差异，比如网页10的飞腾测试采用单通道内存，可能影响发挥。
>
> 用户没明说但可能隐含的需求是：这两款国产芯片在国际竞争中的位置。因此回答中需要补充网页7提到的麒麟X90与苹果M2、Intel i7的对比数据，以及网页1分析的飞腾D2000市场定位，让用户理解不同芯片的战略差异。
>
> 最后要提醒自己避免技术术语堆砌。比如解释“超线程+大小核异构”时（网页7），要关联到“多任务处理更流畅”这样的实际体验；说明飞腾的PSPA1.0安全架构（网页9）时，要强调对政务场景的价值而非纯技术参数。

然后哼哧哼哧一顿输出，至于是否满足我的要求，就要看运气了。碰到这种情况，只能再次和 AI 沟通，针对输出的问题，再下一些明确的指令，一般经过几个来回，也能得到比较满意的答案。

随着 AI 的进化，也懂得在输出前先确认需求，避免无用功。比如下面一段对话：

![](https://raw.githubusercontent.com/mogoweb/mywritings/master/book_wechat/2025/202506/images/i_am_boss_01.png)

这个 AI 就比较聪明了，指令比较模糊的地方，或找我确认之后才进行后面的思考，更为难得的是，AI 还会将需求复述一遍，这样我就可以从它的复述中判断 AI 有没有曲解我的意图。

以前 AI 没有这个深度思考过程，或者说有思考过程，但并没有向我们展现出来。自从 DeepSeek 开创性的引入深度思考模式后，我们终于可以直观的看到 AI 在想些什么，这个员工真的很好用。如果现实中，老板也能了解员工的思考过程，那老板当起来就更容易了。

## 拒绝忽悠

老板要关注的不只是结果，更得识破“假象”，防止被员工忽悠。而 AI 呢？它倒是勤勤恳恳，让干啥就干啥，毫无怨言，24 小时待命，甚至在它根本不懂的情况下，也能给出看似有道理的“解法”。关键在于，AI 从来不会说“不知道”。

这也是使用 AI 的一大风险所在——幻觉。

所谓“幻觉”，就是 AI 一本正经地胡说八道，不仅内容看似合理，还往往有模有样地给出计算步骤、引用数据甚至画图辅助。

科学家目前尚未完全搞清 AI 幻觉的本质原因，而作为用户，我们只能在实践中不断警惕。但即便知道 AI 会犯错，很多时候还是会“中招”。

比如有一次，我在实现一个国密算法时，需要将某个算法的 OID 以 DER 编码形式写入代码。这种繁琐计算当然交给 AI 来处理。AI 也很配合，给出了详细的计算方法、分步讲解以及编码结果：

![](https://raw.githubusercontent.com/mogoweb/mywritings/master/book_wechat/2025/202506/images/i_am_boss_02.png)
![](https://raw.githubusercontent.com/mogoweb/mywritings/master/book_wechat/2025/202506/images/i_am_boss_03.png)

看上去条理清晰、严谨可信。可到了调试阶段，程序始终走不到正确的分支。我才开始怀疑，是不是编码值错了？于是再次求助 AI。

![](https://raw.githubusercontent.com/mogoweb/mywritings/master/book_wechat/2025/202506/images/i_am_boss_04.png)
![](https://raw.githubusercontent.com/mogoweb/mywritings/master/book_wechat/2025/202506/images/i_am_boss_05.png)

AI 毫不脸红的说前面的计算是错误的，并指出错误，更为离谱的是，这次还是给了一个错误的答案。我后来是使用另一个 AI 产品检查代码时，才发现这里的问题。

这次，AI 毫无愧色地承认上次的计算是错的，然后又堂而皇之地给出另一个“正确答案”——但依然是错的。

最终，我是借助另一个 AI 工具重新检查，才发现了问题所在。

从那之后，我也逐渐形成了“老板式”的工作习惯：

* 交叉验证结果，多用几款 AI 工具对同一问题求解，避免“盲信”；

* 对关键环节和关键数据，亲自过一遍；

* 设定“可信指标”，比如输出是否自洽、是否可重现、是否附带验证方法；

拒绝忽悠的前提，是你要比 AI 更有判断力，或者至少懂得：什么不能全信，哪里该另请高明。虽然只有一个员工，管理起来也不简单啊。

## 制定蓝图

制定蓝图

在使用 Cursor IDE 之前，我的使用习惯是将问题原封不动地抛给 AI：贴上一段日志、丢一段代码，让它帮我分析或者修复。但实际效果并不理想，特别是自动编码功能，有时简直像“手滑”——本来只想改一行，结果 AI 哗啦一下，把整个函数甚至整个文件都重写了。

直到公司内部的一次培训，我才了解到 Cursor 有个强大的功能：Cursor Rules。

简单来说，Cursor Rules 就是为 AI 设定行为规范的“指导手册”，它告诉 AI：哪些文件可以改、改动应该遵循哪些编程规范、哪些风格必须保持不变……

以 C++ 为例，一份典型的 Cursor Rule 如下：
```
---
description: 
globs: **/*.c,**/*.cpp,**/*.h,**/*.hpp,**/*.cxx,CMakeLists.txt,*.cmake,conanfile.txt,Makefile,**/*.cc
alwaysApply: false
---
# C++ Programming Guidelines

## Basic Principles
- Use English for all code and documentation.
- Always declare the type of each variable and function.
- Use Doxygen style comments for public APIs.
...
```

这份规则文件就像团队的“编码宪法”，不仅帮助 AI 遵循统一的代码风格、命名规范、函数结构和错误处理方式，还能有效避免它“自作聪明”地大改特改。

Cursor Rules 还能通过 globs 字段指定应用范围，比如只对特定文件类型生效，或者排除测试文件、构建脚本等。此外，它还能配合提示词使用，实现更精细的控制。

从这之后，我开始意识到，真正的“老板”不是让 AI 为所欲为，而是要制定边界、划定责任、给出方向。Cursor Rules 就是我给“AI 员工”立下的操作规章，既保证质量，又提升效率。

它就像一份“蓝图”：不是空喊口号，而是落到实处，从规则、结构、流程、工具一一落实，最终实现“人机协作”的最佳状态。

当我们每天与 AI 互动，在不断甄别、决策、验证的过程中，角色也在潜移默化地转变：从“简单执行者”蜕变为“决策者”，正如老板般掌握全局。同时，拒绝被忽悠和清晰的蓝图，则是让我们在这场智能化革命中立于不败之地的“双重利器”。

希望这篇文章，能帮你更好地理解如何在 AI 时代，真正做一个“老板”——既胸怀大局，又脚踏实地。