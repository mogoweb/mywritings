# 警惕！ AI 用于诈骗 ...

周末的时候，和家人一起去武汉郊外的八分山游玩。回程的时候，发现百度导航的声音，竟然是儿子的声音。原来儿子在我去拿车的时候，闲的无聊，就玩起了百度导航，然后就定制了属于自己的导航语音。不得不佩服小孩子的探索能力，一下子就找到了新的玩法。我问儿子是怎么做的，儿子说就朗读了几段文字，然后上传，过一段时间就可以下载导航语音包了。

显然，这不是简单的录制语音，然后播放出来，而是利用了人工智能，从朗读的语音中提取关键音调信息，然后用于合成语音。这样合成出来的语音

这让我回想起一部电影。在《碟中谍3》中， **靓汤**饰演的 Hunt 特工利用变声技术模仿了一名军火贩子，所用的装备则是一条贴在喉部的贴片，上面布满了电路，实时进行语音变换。在这之前，就逼迫了军火贩子朗读了卡片上的一段文字。

![](https://raw.githubusercontent.com/mogoweb/mywritings/master/book_wechat/202006/images/ai_scam_01.png)

没想到，存在于电影中的高科技，这么快就进入了我们的生活，现代科技真的是发展越来越迅速！

但转念一想，又不寒而栗。如果这项技术被骗子掌握了，我们能识破吗？

前几年，诸如盗取 QQ 号、打电话谎报车祸（病危等）等诈骗手段屡屡见诸报端，直到现在，银行、写字楼、小区满是防止电信诈骗的提示，虽然有所减少，但仍未销声匿迹，不时爆出新闻，仍然有人上当。

如果骗子掌握了这种技术，一定会卷土重来。这已经不是想象，现实生活中已经发生！

> 据《每日邮报》报道，今年 3 月，一名诈骗犯利用 AI 语音模仿软件冒充公司大老板，成功让一家英国能源公司的CEO相信自己正在与德国母公司的老板通电话。
>
> 在电话中，诈骗犯要求这位CEO立即将22万欧元转到匈牙利一家供应商的银行账户，以避免缴纳“滞纳金”，并将转账信息以邮件形式发送，而这位高管毫不犹豫地照做了。最终，这22万欧元一去不复返……

这样的案例也不仅仅发生在国外。下面发生在国内的故事可不是杜撰出来的。

> 刘倩突然收到一条来自多年不联系好友的微信消息，“最近在忙什么？”“要不要见一面？”
>
> 从打招呼、互相寒暄到吐槽近况，整个聊天过程自然而然。她感叹几年过去了，好友仍是语气可爱的“软萌妹子”，甚至记得她们曾在北京隆冬的某一天晚上在街头分食一份煎饼。
>
> 聊天就这样切换到语音，好友开始找她借钱，数额不大， 2000 块。她毫不犹豫地转过去了。紧接着好友第二次、第三次向她借钱，她开始察觉事情有些不对。
>
> 事情确实不对，刘倩没想到，那个声音、语气一如既往地熟悉，甚至能清晰记得他们多年前共同经历的“好友”是个诈骗犯。
>
> 骗子在获取了刘倩好友的声音素材之后，用 AI 合成的“好友”声音与之对话；熟悉的语气和共同的回忆则“归功于” AI 在网上搜集分析了刘倩微信、微博等个人信息。

如果说单凭语音不可信，那视频总没有问题吧？

也有问题。借助于 AI 的快速发展，影像造假也越来越简单，越来越难以识别。还记得之前闹得沸沸扬扬的 Deepfake 视频吧？借助于 AI 换脸技术，将明星的脸换到色情视频里，有多名明星中招。

骗子的嗅觉往往比普通人更加灵敏，立刻就应用到诈骗上。比如，不久前就有骗子用 AI 将自己合成假王源，在直播平台上大肆行骗，引得粉丝纷纷来刷礼物。

![真假王源](https://raw.githubusercontent.com/mogoweb/mywritings/master/book_wechat/202006/images/ai_scam_02.jpeg)

前两个月，芒果台播出了一部新电视剧《三千鸦杀》，由于剧中饰演一个角色的女演员被解约了，但是戏已经杀青，重拍代价太大，芒果台选择使用了 AI 换脸，结果引发网友的找 BUG 热情。对于一部高清晰度的影片，眼尖的网友可能会找出换脸的迹象。如果在视频通话中，清晰度没那么高，特别是没有防备的情况下，我们还能识破吗？

这只是 AI 诈骗的冰山一角。当人们还在感叹区区毛骗，何足挂齿的时候，有骗子已经把 AI 这门新技术运用得炉火纯青 — 算法筛选被骗群体、分析你的个人特点和喜好，机器人定时拨打骚扰电话，再加上换脸、变声等一系列操作，让人想不相信骗子是你都难。

总的来说，目前运用 AI 技术进行诈骗的方式一共有四种：

1. 转发微信语音。骗子通过盗取微信号，然后提出转账要求，多数人会选择要求对方语音回复，这时骗子会转发之前的语音，从而获取信任，进而获得钱款。虽然目前微信语音是不能转发的，但骗子可以通过提取语音文件或者安装增强版微信(一般是基于xposed框架的插件),实现转发语音。

2. 声音合成。也是目前发生频率最高的 AI 诈骗方式。骗子通过骚扰电话等方式，录音提取某人的声音，并对素材进行合成，用伪造的声音实施诈骗。

3. AI 换脸。视频通话的可信度明显高于语音和电话，利用AI换脸，骗子可以伪装成任何人。

4. 通过 AI 技术筛选受骗人群，获取受骗者的聊天习惯、生活特性等。通过分析公众发布在网上的各类信息，骗子会根据所要实施的骗术对人群进行筛选，从而选出目标人群。例如实施情感诈骗时，可以筛选出经常发布感情信息的人群；实施金融诈骗时，可以筛选出经常搜集投资信息的人群。

目前 AI 诈骗还没有那么普遍，一来是门槛比较高，二来目前的技术还不是那么完美，比如 AI 换脸，偶尔会出现穿帮。但是回想起之前的电信诈骗，都是先在小范围报道，然后扩散到全国。中国各地发展不平衡，一般等骗术传到偏远农村，才最终结束一轮，这时骗子又开始新的一轮骗术。因此，在 AI 诈骗术还没有大规模应用之前，请把相关的骗术传播开来，让大家擦亮双眼，也让骗子无处可遁。

面对一轮又一轮的新诈骗术，我们该如何防范呢？

第一是验证。提高警惕是防范诈骗的最好方式，在涉及钱款时，群众要提高安全意识，通过电话、视频等方式确认对方是否为本人，在不能确定真实身份时，可将到账时间设定为“2小时到账”或“24小时到账”,以预留处理时间。此外，可以选择向对方银行汇款，避免通过微信等社交工具转账。因微信等工具均会绑定银行卡，向对方银行卡转账，一方面便于核实对方信息，确认钱款去向；另一方面，对方能通过短信通知得知转账信息，此外，即使是本人操作，也不影响对方提取钱款。

第二是保护个人信息，注重隐私保护。社交平台的发展加大了保护个人信息的难度，民众将越多的个人信息暴露在网络上，遭受诈骗的概率越高。实施诈骗需要获取当事人的个人信息，网络共享加上 AI 技术，骗子搜集整理当事人的个人信息更为便捷。因此，为避免骗子借用个人信息实施诈骗，民众应当加强个人信息保护意识，以防止骗子利用 AI 技术掌握大量个人信息并对人物性格、需求倾向等进行刻画，从而有针对性地实施诈骗。

我们也不能因为 AI 技术被犯罪份子利用，就禁止发展技术，技术的问题，也可以通过技术加以解决。目前，将 AI 技术用于提升反诈骗精准度，也取得了一定的效果。比如，利用以大数据分析和智能预警算法为基础的 AI 技术进行反网络诈骗，在工信部等部门的主导下，利用大数据优势，将相关数据通过反诈骗机制进行共享，进而提高反诈骗的精准度。

道高一尺，魔高一丈，还有一种说法是魔高一尺，道高一丈。相信诈骗与反诈骗之间的技术会一直对抗下去，就如同病毒与反病毒，促进技术的发展，最终会给人类带来更多的福祉。

骗子都在积极拥抱人工智能，你呢？

![](https://raw.githubusercontent.com/mogoweb/mywritings/master/book_wechat/common_images/%E5%BE%AE%E4%BF%A1%E5%85%AC%E4%BC%97%E5%8F%B7_%E5%85%B3%E6%B3%A8%E4%BA%8C%E7%BB%B4%E7%A0%81.png)