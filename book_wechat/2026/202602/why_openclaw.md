# OpenClaw为何爆火？普通程序员能得到哪些启发？

在上篇文章《[deepin v25 下 OpenClaw 安装教程 + 飞书接入](https://mp.weixin.qq.com/s/DyAHXpX2WHM01H4f9la_fg)》中介绍了OpenClaw 的部署。不少朋友看完后的第一反应是：怎么这么麻烦？

有这种感觉，其实很正常，甚至可以说是“对的”。OpenClaw 本身诞生于开源社区，没有大公司背书，也并非面向大众用户设计，它更适合那些愿意折腾、愿意为自由和可控性付出时间成本的技术爱好者。如果你追求的是开箱即用、流程顺滑、几乎不需要配置的体验，那 OpenClaw 目前显然还不是最合适的选择，或许需要等待更成熟的产品形态。

也有已经上手尝试的朋友反馈：用下来感觉也就那样。它既没有自研的大模型，也看不到多么复杂的算法，也就是没有什么护城河，会不会有点被过度吹捧了？

关于这一点，我在之前的文章《[以史为鉴，参照互联网的发展历程，AI 发展到哪个阶段了？](https://mp.weixin.qq.com/s/KrDStQjDAPKwEO2XhECqPw)》中其实已经做过分析。AI 发展到后期，必然会像互联网一样，**应用为王**。

尽管媒体不断强调“AI 时代已经到来”，但对大多数普通用户而言，这种变化的体感并不强烈。现阶段，很多人对 AI 的认知，仍停留在即时问答、文本生成、对话式助手层面，本质上只是把 AI 当成了一个更聪明的搜索引擎。

换句话说，当前的 AI 依然缺乏真正的“行动能力”——它还不能像一个助手那样，替我们完成查日程、订机票、处理事务等一系列具体操作。而这，恰恰是 OpenClaw 试图补齐的那块拼图。

## 为什么 OpenClaw 会突然爆火？

与传统的 AI 如 ChatGPT 不同，OpenClaw 本质上是一个**开源的个人AI代理网关**，运行在用户自己的设备上。如果说以前的 AI 像是一个知识渊博的顾问，坐在对面回答你的问题；而 OpenClaw 则更像是一个**挽起袖子直接动手的实干派**，它拥有你电脑的操作权限，可以真正执行任务。

**“它发现我没起床，直接SSH连回我伦敦的家里，把音响开到最大轰炸我。”** 这不是科幻电影情节，而是 OpenClaw 创作者 Peter Steinberger 在摩洛哥旅行时的真实经历。

OpenClaw 有三个核心突破点：

**1. 真正的“执行力”而非仅仅“对话能力”**

你可以通过 WhatsApp、Telegram、钉钉等日常通讯工具向 OpenClaw 发送指令：“帮我把下载文件夹里所有的 PDF 按年份归档并列出清单”。它会**真的去操作你的电脑**，完成读取、整理、移动和汇报的全过程。

**2. 本地优先与数据主权**

你的所有数据——聊天记录、API密钥、文件文档都存储在本地。这种对数据的绝对掌控权，在隐私泄露频发的时代显得尤为珍贵。

**3. 持久记忆与主动行为**

OpenClaw 拥有“心跳机制”和持久记忆，可以像真正的助理一样记住你的偏好，并**主动提醒或执行任务**。例如，它发现你三周没联系某位朋友，会自动扫描该朋友的社交媒体，发现他在城里后，会问你要不要约饭。

所以，OpenClaw的迅速走红并非偶然，它精准击中了当前AI应用的几个核心痛点：

* **传统自动化工具的局限性**：以往的自动化工具需要大量手动配置，而 OpenClaw 通过自然语言交互大幅降低了使用门槛。

* **云端AI的隐私担忧**：随着企业对数据控制的加强，越来越多的用户希望将敏感数据保留在本地。

* **从“辅助”到“代理”的转变需求**：市场不再满足于仅能提供建议的AI，而是需要能够**直接执行任务**的智能代理。

当然，OpenClaw 的爆火也带来了巨大的争议，在授予 AI 执行能力的同时，也会让渡一部分权利。所以现在的问题在于，我们能够相信 AI 吗？如果 AI 删除了电脑上的重要数据，谁来背锅，如何问责？

使用 OpenClaw 可能面临以下主要安全风险：

1. **设计缺陷与不当暴露** 
   * **公网暴露风险**：为了远程访问便利，部分用户将 OpenClaw 服务监听地址改为`0.0.0.0`，导致其控制端口（如18789）直接暴露在公网。若未配置强认证，攻击者可通过网络扫描工具直接发现并控制这些实例，窃取其中存储的API密钥、聊天记录等敏感信息。 
   * **供应链攻击风险**：OpenClaw 的扩展技能库（如ClawdHub）若缺乏严格审核，攻击者可上传恶意技能包。这些技能被下载后，可能在用户环境中执行危险操作，构成供应链攻击。

2. **架构性核心漏洞** 
   * **间接提示注入**：这是代理式AI的结构性弱点。攻击者可将恶意指令隐藏于AI处理的邮件、网页或文档中。AI在读取这些内容时，可能无法区分正常信息与恶意指令，从而执行如发送私钥、删除文件等危险操作。传统安全防护对此类攻击难以有效拦截。 
   * **本地信任绕过**：OpenClaw 默认信任本地回环地址的连接。当用户在前端部署反向代理（如Nginx）以增强安全时，若配置不当，所有经代理转发的请求都可能被误判为可信的本地流量，导致身份验证机制被绕过。

3. **权限滥用与操作失控**
   * **过度权限与误操作**：以高权限（如root）运行AI代理时，其操作偏差或对模糊指令的误解，可能导致系统文件被误删、关键配置被篡改等严重后果。
   * **数据存储风险**：用户与AI的交互历史、敏感信息可能以明文形式（如Markdown、JSON文件）存储在本地。若设备被恶意软件感染，这些数据极易被盗。

## 从 Manus，到 OpenClaw：普通程序员的机会

聊到 OpenClaw，很多人会不自觉想到 manus，就是[一家被反复质疑，却最终被 Meta 看中的公司](https://mp.weixin.qq.com/s/iltvsl_I2aiWVwLjBYcXOg)这篇文章中提到的那个卖了 20 亿美金的 AI 初创公司。一个只有几百号人的小公司，就能有这么高的估值，让人感觉回到了 2000 年的互联网泡沫时期。

很多程序员一看到 AI，就会下意识地焦虑：“模型我也不会，算法我也不懂，是不是要被淘汰了？”

其实，从最近一波又一波爆火的 AI 项目可以看到，大模型不是普通程序员的主战场。真正的机会，反而出现在 Agent 这一层。

普通程序员可以抓住的三个方向：

1. **把现实世界拆成可执行流程**

这是程序员最擅长的事情。现实中的工作：

- 模糊
- 充满例外
- 强依赖规则和边界

谁能把一个复杂事务拆解成清晰、可控、可回滚的流程，谁就在 AI 时代拥有稀缺能力。

2. **给不安全的 AI套上工程化的安全壳**

像 OpenClaw 这样的 Agent，本质上是不安全的。它太自由了。而程序员恰恰最擅长处理这些问题：

- 权限控制
- 沙箱隔离
- 限流
- 审计
- 回滚机制

未来会出现大量并不显眼，但极其关键的角色：不是教 AI 思考，而是约束 AI 行为。

这不是 Prompt 工程，而是工程能力本身的延伸。

3. **在细分场景里，做半自动化的 AI 工具**

注意一个关键词：半自动化。

不是做通用 AI，也不是做“万能助手”，而是：

* 给财务用的 Agent
* 给运维用的 Agent
* 给内容编辑用的 Agent
* 给行政、HR 用的 Agent

这些场景的共同点是：

* 场景窄
* 规则多
* 容错率低
* 强依赖流程

大厂不一定愿意做，通用产品也很难覆盖，但对懂工程、懂业务的程序员来说，反而是机会。

## 结语

技术变革的步伐从未停歇。从PC互联网到移动互联网，再到如今的AI智能体时代，每一次变革都重塑着程序员的核心竞争力。

OpenClaw的爆火不是终点，而是一个新的起点。它预示着AI正在从“辅助”走向“主导”，从“回答问题”走向“执行任务”。对于有准备的程序员来说，这不仅是挑战，更是前所未有的机遇。

你准备好迎接这个未来了吗？